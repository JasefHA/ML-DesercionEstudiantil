{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CARGO DATAFRAMES BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ruta_export = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\export\"\n",
    "ruta_output = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\output\"\n",
    "ruta_sources = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\sources\"\n",
    "\n",
    "df_matriculados_2024_1 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2024_1.csv'))\n",
    "df_matriculados_2023_2 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2023_2.csv'))\n",
    "df_matriculados_2023_1 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2023_1.csv'))\n",
    "df_matriculados_2022_2 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2022_2.csv'))\n",
    "df_matriculados_2022_1 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2022_1.csv'))\n",
    "\n",
    "\n",
    "df_desertores_2023_2 = pd.read_csv(os.path.join(ruta_export,'Desertores_2023_2.csv'))\n",
    "\n",
    "df_variables = pd.read_csv(os.path.join(ruta_export,'DataMaestra_Estudiante.csv'))\n",
    "\n",
    "df_notas_2023_2 = pd.read_csv(os.path.join(ruta_sources,'DATA_DETALLE_NOTAS-2023-2.csv'))\n",
    "\n",
    "df_colegio_procedencia = pd.read_csv(\n",
    "    os.path.join(ruta_sources, 'DATA_COLEGIO_PROCEDENCIA.csv'),\n",
    "    header=None,  # Indica que el archivo no tiene cabeceras\n",
    "    names=['IdAlumno', 'Colegio', 'TipoColegio']  # Especificar las cabeceras manualmente\n",
    ")\n",
    "\n",
    "nota_aprobatoria = 13\n",
    "notas_desaprobadas = 9\n",
    "periodo = '2023-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTENGO VARIABLES RELACIONADAS A NOTAS\n",
    "### Parciales Desaprobados\n",
    "### Finales Desaprobados\n",
    "### Flag Excede Notas Desaprobadas No Parciales No Finales\n",
    "### Flag que indica si la cantidad de cursos desaprobados excede o es igual al 50% del total de cursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    IdAlumno  CantParcialesDesaprobados  CantFinalesDesaprobados  \\\n",
      "0  100002894                          0                        0   \n",
      "1  100003558                          3                        3   \n",
      "2  100003932                          1                        0   \n",
      "3  100003946                          2                        3   \n",
      "4  100003989                          0                        0   \n",
      "\n",
      "  ExcedeNotasDesaprobadasNoParcNoFin ExcedeMitadCursosDesaprobados  \\\n",
      "0                                 NO                            NO   \n",
      "1                                 NO                            SI   \n",
      "2                                 NO                            NO   \n",
      "3                                 NO                            NO   \n",
      "4                                 NO                            NO   \n",
      "\n",
      "                     ProgramaAlu  \n",
      "0          Nutrición y Dietética  \n",
      "1  Medic Veterinaria y Zootecnia  \n",
      "2                Medicina Humana  \n",
      "3  Medic Veterinaria y Zootecnia  \n",
      "4                     Psicología  \n"
     ]
    }
   ],
   "source": [
    "# Agrupar por IdAlumno y contar los registros de parciales y finales desaprobados\n",
    "df_cant_desaprobado_agrupado = df_notas_2023_2.groupby('IdAlumno').agg(\n",
    "    CantParcialesDesaprobados=(\n",
    "        'Actividad', \n",
    "        lambda x: ((x == 'EVALUACION PARCIAL') & (df_notas_2023_2.loc[x.index, 'NotaActiv'] < nota_aprobatoria)).sum()\n",
    "    ),\n",
    "    CantFinalesDesaprobados=(\n",
    "        'Actividad', \n",
    "        lambda x: ((x == 'EVALUACION FINAL') & (df_notas_2023_2.loc[x.index, 'NotaActiv'] < nota_aprobatoria)).sum()\n",
    "    ),\n",
    "    # Columna auxiliar para contar las evaluaciones diferentes de PARCIAL y FINAL desaprobadas\n",
    "    CantNotasDesaprobadasNoParcNoFin=(\n",
    "        'Actividad', \n",
    "        lambda x: ((~x.isin(['EVALUACION PARCIAL', 'EVALUACION FINAL', 'EVALUACION DIAGNOSTICA'])) & (df_notas_2023_2.loc[x.index, 'NotaActiv'] < nota_aprobatoria)).sum()\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "# Crear la columna 'ExcedeNotasDesaprobadasNoParcNoFin'\n",
    "df_cant_desaprobado_agrupado['ExcedeNotasDesaprobadasNoParcNoFin'] = df_cant_desaprobado_agrupado['CantNotasDesaprobadasNoParcNoFin'].apply(\n",
    "    lambda x: 'SI' if x >= notas_desaprobadas else 'NO'\n",
    ")\n",
    "\n",
    "# Eliminar la columna 'CantNotasDesaprobadasNoParcNoFin' \n",
    "df_cant_desaprobado_agrupado.drop(columns=['CantNotasDesaprobadasNoParcNoFin'], inplace=True)\n",
    "\n",
    "# Calcular la nota final para cada curso por alumno\n",
    "df_notas_2023_2['NotaFinalCurso'] = np.where(\n",
    "    df_notas_2023_2['Actividad'] != 'EVALUACION DIAGNOSTICA',\n",
    "    (df_notas_2023_2['Peso'] * df_notas_2023_2['NotaActiv']) / 100,\n",
    "    np.nan  # Ignoramos las actividades diagnósticas\n",
    ")\n",
    "\n",
    "# Agrupar por IdAlumno y Curso para obtener la nota final por curso\n",
    "df_notas_finales_por_curso = df_notas_2023_2.groupby(['IdAlumno', 'Curso']).agg(\n",
    "    NotaFinalCurso=('NotaFinalCurso', 'sum')  # Sumar las notas ponderadas por curso\n",
    ").reset_index()\n",
    "\n",
    "# Redondeo las notas a su entero más cercano para el posterior conteo \n",
    "df_notas_finales_por_curso['NotaFinalCurso'] = df_notas_finales_por_curso['NotaFinalCurso'].round()\n",
    "\n",
    "# Agrupar por IdAlumno y contar los cursos desaprobados\n",
    "df_cursos_desaprobados = df_notas_finales_por_curso.groupby('IdAlumno').agg(\n",
    "    CantCursosDesaprobados=(\n",
    "        'NotaFinalCurso', \n",
    "        lambda x: (x < nota_aprobatoria).sum()\n",
    "    ),\n",
    "    CantCursos=(\n",
    "        'NotaFinalCurso', \n",
    "        'count'  # Cuenta la cantidad de cursos\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "# Creamos la columna ExcedeMitadCursosDesaprobados\n",
    "df_cursos_desaprobados['ExcedeMitadCursosDesaprobados'] = df_cursos_desaprobados.apply(\n",
    "    lambda row: 'SI' if (row['CantCursosDesaprobados'] / row['CantCursos']) >= 0.5 else 'NO', axis=1\n",
    ")\n",
    "\n",
    "# Eliminar la columna 'CantNotasDesaprobadasNoParcNoFin' \n",
    "df_cursos_desaprobados.drop(columns=['CantCursosDesaprobados','CantCursos'], inplace=True)\n",
    "\n",
    "# Unir este resultado con el DataFrame anterior\n",
    "df_cant_desaprobado_agrupado = df_cant_desaprobado_agrupado.merge(\n",
    "    df_cursos_desaprobados, \n",
    "    on='IdAlumno', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_cant_desaprobado_agrupado = df_cant_desaprobado_agrupado.merge(\n",
    "    df_notas_2023_2[['IdAlumno', 'ProgramaAlu']].drop_duplicates(),  # Tomar IdAlumno y ProgramaAlu sin duplicados\n",
    "    on='IdAlumno',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Visualizar el DataFrame final\n",
    "print(df_cant_desaprobado_agrupado.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Identificación de alumnos a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         IdAlumno CicloLectivoDesCorta\n",
      "14      100004070               2023-2\n",
      "46      100008630               2023-2\n",
      "48      100009785               2023-2\n",
      "62      100011191               2023-2\n",
      "86      100012563               2023-2\n",
      "...           ...                  ...\n",
      "20656   180000324               2023-2\n",
      "20673   180000558               2023-2\n",
      "20745   180000790               2023-2\n",
      "21058  4200710473               2023-2\n",
      "21061  4200810288               2023-2\n",
      "\n",
      "[1205 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Lista de DataFrames a combinar dinámicamente\n",
    "dfs_matriculados = [df_matriculados_2023_1, df_matriculados_2022_2, df_matriculados_2022_1, df_matriculados_2023_2]\n",
    "\n",
    "# Concatenar todos los DataFrames\n",
    "df_matriculados_todos = pd.concat(dfs_matriculados)\n",
    "\n",
    "# Agrupar por 'IdAlumno' y obtener el mínimo valor de 'CicloLectivoDesCorta'\n",
    "df_matriculados_agrupados = df_matriculados_todos.groupby(['IdAlumno']).agg({'CicloLectivoDesCorta': 'min'}).reset_index()\n",
    "\n",
    "\n",
    "# Filtrar los alumnos cuyo mínimo 'CicloLectivoDesCorta' sea igual al valor definido\n",
    "df_nuevos_matriculados = df_matriculados_agrupados[df_matriculados_agrupados['CicloLectivoDesCorta'] == periodo]\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_nuevos_matriculados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        IdAlumno CicloLectivoDesCorta  Desercion\n",
      "0      100004070               2023-2          0\n",
      "1      100008630               2023-2          0\n",
      "2      100009785               2023-2          0\n",
      "3      100011191               2023-2          1\n",
      "4      100012563               2023-2          1\n",
      "...          ...                  ...        ...\n",
      "1200   180000324               2023-2          1\n",
      "1201   180000558               2023-2          0\n",
      "1202   180000790               2023-2          0\n",
      "1203  4200710473               2023-2          1\n",
      "1204  4200810288               2023-2          1\n",
      "\n",
      "[1205 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Realizar el cruce con el DataFrame de desertores\n",
    "df_nuevos_matriculados = df_nuevos_matriculados.merge(\n",
    "    df_desertores_2023_2[['IdAlumno']], \n",
    "    on='IdAlumno', \n",
    "    how='left', \n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Crear la columna 'Desercion' donde se marca con 1 si está en df_desertores_2023_2 ('both') y 0 si no está ('left_only')\n",
    "df_nuevos_matriculados['Desercion'] = df_nuevos_matriculados['_merge'].apply(lambda x: 1 if x == 'both' else 0)\n",
    "\n",
    "# Eliminar la columna '_merge' que se creó con el indicador\n",
    "df_nuevos_matriculados.drop(columns=['_merge'], inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame resultante con la nueva columna 'Desercion'\n",
    "print(df_nuevos_matriculados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validacion de alumno que no debe aparecer para 2023-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [IdAlumno, CicloLectivoDesCorta, Desercion]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame para encontrar el registro específico\n",
    "resultado = df_nuevos_matriculados[df_nuevos_matriculados['IdAlumno'] == 100118394]\n",
    "\n",
    "# Verifica el resultado\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSTRUYO UN SOLO DATAFRAME CON TODAS LAS VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    IdAlumno CicloLectivoDesCorta  Desercion Genero FechaNacimiento Distrito  \\\n",
      "0  100004070               2023-2          0    NaN             NaN      NaN   \n",
      "1  100008630               2023-2          0    NaN             NaN      NaN   \n",
      "2  100009785               2023-2          0    NaN             NaN      NaN   \n",
      "3  100011191               2023-2          1    NaN             NaN      NaN   \n",
      "4  100012563               2023-2          1    NaN             NaN      NaN   \n",
      "\n",
      "  Provincia Departamento FamiliarResponsable  AnioNacimiento  \\\n",
      "0       NaN          NaN                 NaN             NaN   \n",
      "1       NaN          NaN                 NaN             NaN   \n",
      "2       NaN          NaN                 NaN             NaN   \n",
      "3       NaN          NaN                 NaN             NaN   \n",
      "4       NaN          NaN                 NaN             NaN   \n",
      "\n",
      "   CantParcialesDesaprobados  CantFinalesDesaprobados  \\\n",
      "0                          0                        0   \n",
      "1                          0                        0   \n",
      "2                          2                        1   \n",
      "3                          6                        6   \n",
      "4                          0                        0   \n",
      "\n",
      "  ExcedeNotasDesaprobadasNoParcNoFin ExcedeMitadCursosDesaprobados  \\\n",
      "0                                 SI                            NO   \n",
      "1                                 NO                            NO   \n",
      "2                                 NO                            SI   \n",
      "3                                 SI                            NO   \n",
      "4                                 NO                            NO   \n",
      "\n",
      "                    ProgramaAlu                   Colegio TipoColegio  \n",
      "0  Ing. Económica y de Negocios     Saco Oliveros - S.J.M        PRIV  \n",
      "1  Ing. Negocios Agroforestales              Trilce Comas        PRIV  \n",
      "2  Arquitectura y Urb Ambiental  Colegio Fuera De Cartera        PRIV  \n",
      "3                 Estomatología  Colegio Fuera De Cartera        PRIV  \n",
      "4               Medicina Humana          2da Especialidad        PRIV  \n"
     ]
    }
   ],
   "source": [
    "#Variables CRM\n",
    "df = pd.merge(df_nuevos_matriculados, df_variables, on='IdAlumno', how='left')\n",
    "\n",
    "#Parciales Desaprobados\n",
    "df = pd.merge(df, df_cant_desaprobado_agrupado, on='IdAlumno', how='left')\n",
    "\n",
    "#Colegio Procedencia\n",
    "df = pd.merge(df,df_colegio_procedencia, on='IdAlumno', how='left')\n",
    "\n",
    "\n",
    "# columna objetivo\n",
    "df['Desercion'] = df['IdAlumno'].isin(df_desertores_2023_2['IdAlumno']).astype(int)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 17)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.to_csv('cachimbos_2023_2_nulos.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdAlumno                                0\n",
      "CicloLectivoDesCorta                    0\n",
      "Desercion                               0\n",
      "Genero                                 90\n",
      "FechaNacimiento                        90\n",
      "Distrito                               90\n",
      "Provincia                              90\n",
      "Departamento                           90\n",
      "FamiliarResponsable                   745\n",
      "AnioNacimiento                         90\n",
      "CantParcialesDesaprobados               0\n",
      "CantFinalesDesaprobados                 0\n",
      "ExcedeNotasDesaprobadasNoParcNoFin      0\n",
      "ExcedeMitadCursosDesaprobados           0\n",
      "ProgramaAlu                             0\n",
      "Colegio                                 0\n",
      "TipoColegio                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN GENERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdAlumno                                0\n",
      "CicloLectivoDesCorta                    0\n",
      "Desercion                               0\n",
      "Genero                                  0\n",
      "FechaNacimiento                        90\n",
      "Distrito                               90\n",
      "Provincia                              90\n",
      "Departamento                           90\n",
      "FamiliarResponsable                   745\n",
      "AnioNacimiento                         90\n",
      "CantParcialesDesaprobados               0\n",
      "CantFinalesDesaprobados                 0\n",
      "ExcedeNotasDesaprobadasNoParcNoFin      0\n",
      "ExcedeMitadCursosDesaprobados           0\n",
      "ProgramaAlu                             0\n",
      "Colegio                                 0\n",
      "TipoColegio                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la cuenta de cada género y de los valores nulos\n",
    "conteo_generos = df['Genero'].value_counts(dropna=False)\n",
    "count_f = conteo_generos.get('F', 0)  # Cantidad de F\n",
    "count_m = conteo_generos.get('M', 0)  # Cantidad de M\n",
    "total_blancos = conteo_generos.get(np.nan, 0)  # Cantidad de valores nulos\n",
    "\n",
    "# Ahora, calculamos la distribución equitativa\n",
    "if total_blancos > 0:\n",
    "    # Proporciones de cada género\n",
    "    proporciones_f = count_f / (count_f + count_m)\n",
    "    proporciones_m = count_m / (count_f + count_m)\n",
    "\n",
    "    # Cálculo de cuántos géneros se asignarán a los valores nulos\n",
    "    asignacion_f = int(total_blancos * proporciones_f)\n",
    "    asignacion_m = total_blancos - asignacion_f  # Lo que queda se asigna a M\n",
    "\n",
    "    # Rellenar los valores nulos en el DataFrame\n",
    "    df.loc[df['Genero'].isna(), 'Genero'] = ['F'] * asignacion_f + ['M'] * asignacion_m\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN FECHA DE NACIMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdAlumno                                0\n",
      "CicloLectivoDesCorta                    0\n",
      "Desercion                               0\n",
      "Genero                                  0\n",
      "FechaNacimiento                         0\n",
      "Distrito                               90\n",
      "Provincia                              90\n",
      "Departamento                           90\n",
      "FamiliarResponsable                   745\n",
      "AnioNacimiento                          0\n",
      "CantParcialesDesaprobados               0\n",
      "CantFinalesDesaprobados                 0\n",
      "ExcedeNotasDesaprobadasNoParcNoFin      0\n",
      "ExcedeMitadCursosDesaprobados           0\n",
      "ProgramaAlu                             0\n",
      "Colegio                                 0\n",
      "TipoColegio                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar cuántos valores nulos hay en FechaNacimiento\n",
    "n = df['FechaNacimiento'].isnull().sum()\n",
    "\n",
    "# Función para generar fechas aleatorias en el formato 'YYYY-MM-DD'\n",
    "def generar_fecha_aleatoria(n):\n",
    "    fechas = []\n",
    "    for _ in range(n):\n",
    "        anio = np.random.choice([2006, 2007])  # Años para tener 16 o 17 años en 2023\n",
    "        mes = np.random.randint(1, 13)  # Mes de 1 a 12\n",
    "        dia = np.random.randint(1, 29)  # Día de 1 a 28 (para simplificar)\n",
    "        fecha = f\"{anio}-{mes:02d}-{dia:02d}\"  # Formato 'YYYY-MM-DD'\n",
    "        fechas.append(fecha)\n",
    "    return fechas\n",
    "\n",
    "# Generar fechas aleatorias y rellenar los nulos\n",
    "fechas_aleatorias = generar_fecha_aleatoria(n)\n",
    "df.loc[df['FechaNacimiento'].isnull(), 'FechaNacimiento'] = fechas_aleatorias\n",
    "\n",
    "# Obtener el año de nacimiento de los nulos en FechaNacimiento\n",
    "df.loc[df['AnioNacimiento'].isnull(), 'AnioNacimiento'] = df['FechaNacimiento'].str.split('-').str[0].astype(int)\n",
    "\n",
    "#print(df)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN DISTRITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdAlumno                                0\n",
      "CicloLectivoDesCorta                    0\n",
      "Desercion                               0\n",
      "Genero                                  0\n",
      "FechaNacimiento                         0\n",
      "Distrito                                0\n",
      "Provincia                              90\n",
      "Departamento                           90\n",
      "FamiliarResponsable                   745\n",
      "AnioNacimiento                          0\n",
      "CantParcialesDesaprobados               0\n",
      "CantFinalesDesaprobados                 0\n",
      "ExcedeNotasDesaprobadasNoParcNoFin      0\n",
      "ExcedeMitadCursosDesaprobados           0\n",
      "ProgramaAlu                             0\n",
      "Colegio                                 0\n",
      "TipoColegio                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lista de distritos para rellenar\n",
    "distritos = [\"ATE\", \"VILLA EL SALVADOR\", \"COMAS\", \"CHORRILLOS\", \"SAN MARTÍN DE PORRES\"]\n",
    "\n",
    "# Contar cuántos valores nulos hay en el campo 'Distrito'\n",
    "nulos_distrito = df['Distrito'].isnull().sum()\n",
    "\n",
    "# Calcular cuántos registros de cada distrito se necesitan\n",
    "if nulos_distrito > 0:\n",
    "    # Calcular cuántos distritos asignar a cada uno\n",
    "    asignaciones = [nulos_distrito // len(distritos)] * len(distritos)\n",
    "    \n",
    "    # Distribuir los restantes de manera aleatoria entre los distritos\n",
    "    for i in range(nulos_distrito % len(distritos)):\n",
    "        asignaciones[i] += 1\n",
    "\n",
    "    # Crear una lista con los distritos asignados\n",
    "    distritos_asignados = []\n",
    "    for distrito, cantidad in zip(distritos, asignaciones):\n",
    "        distritos_asignados.extend([distrito] * cantidad)\n",
    "\n",
    "    # Mezclar aleatoriamente la lista para distribuir uniformemente\n",
    "    np.random.shuffle(distritos_asignados)\n",
    "\n",
    "    # Rellenar los valores nulos en el DataFrame\n",
    "    df.loc[df['Distrito'].isnull(), 'Distrito'] = distritos_asignados\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN PROVINCIA NI DEPARTAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdAlumno                                0\n",
      "CicloLectivoDesCorta                    0\n",
      "Desercion                               0\n",
      "Genero                                  0\n",
      "FechaNacimiento                         0\n",
      "Distrito                                0\n",
      "Provincia                               0\n",
      "Departamento                            0\n",
      "FamiliarResponsable                   745\n",
      "AnioNacimiento                          0\n",
      "CantParcialesDesaprobados               0\n",
      "CantFinalesDesaprobados                 0\n",
      "ExcedeNotasDesaprobadasNoParcNoFin      0\n",
      "ExcedeMitadCursosDesaprobados           0\n",
      "ProgramaAlu                             0\n",
      "Colegio                                 0\n",
      "TipoColegio                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Provincia'] = df['Provincia'].fillna('LIMA')\n",
    "df['Departamento'] = df['Departamento'].fillna('LIMA')\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREO CAMPO ANIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la columna 'ANIO' tomando los primeros 4 caracteres de 'CicloLectivoDesCorta'\n",
    "df['Anio'] = df['CicloLectivoDesCorta'].str[:4].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREO CAMPO EDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdAlumno                                0\n",
      "CicloLectivoDesCorta                    0\n",
      "Desercion                               0\n",
      "Genero                                  0\n",
      "FechaNacimiento                         0\n",
      "Distrito                                0\n",
      "Provincia                               0\n",
      "Departamento                            0\n",
      "FamiliarResponsable                   745\n",
      "AnioNacimiento                          0\n",
      "CantParcialesDesaprobados               0\n",
      "CantFinalesDesaprobados                 0\n",
      "ExcedeNotasDesaprobadasNoParcNoFin      0\n",
      "ExcedeMitadCursosDesaprobados           0\n",
      "ProgramaAlu                             0\n",
      "Colegio                                 0\n",
      "TipoColegio                             0\n",
      "Anio                                    0\n",
      "Edad                                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Edad'] = df['Anio'] - df['AnioNacimiento']\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Edad  GrupoEdad\n",
      "0  17.0  MenosDe18\n",
      "1  16.0  MenosDe18\n",
      "2  16.0  MenosDe18\n",
      "3  17.0  MenosDe18\n",
      "4  17.0  MenosDe18\n"
     ]
    }
   ],
   "source": [
    "# Definir las condiciones y sus correspondientes etiquetas\n",
    "condiciones = [\n",
    "    (df['Edad'] <= 18),\n",
    "    (df['Edad'] > 18) & (df['Edad'] < 25),\n",
    "    (df['Edad'] >= 25)\n",
    "]\n",
    "\n",
    "etiquetas = ['MenosDe18', 'Entre18y25', 'Mayor25']\n",
    "\n",
    "# Crear la nueva columna 'GrupoEdad' con las etiquetas según las condiciones, usando un valor por defecto como ''\n",
    "df['GrupoEdad'] = np.select(condiciones, etiquetas, default='')\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['Edad', 'GrupoEdad']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO EL FAMILIAR RESPONSABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filas donde FamiliarResponsable es nulo\n",
    "mask = df['FamiliarResponsable'].isnull()\n",
    "\n",
    "# Aplicar la condición solo a esas filas\n",
    "df.loc[mask, 'FamiliarResponsable'] = df.loc[mask, 'Edad'].apply(lambda x: 'Apoderado' if x <= 18 else 'Alumno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO EL TIPO DE COLEGIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TipoColegio'] = df_colegio_procedencia['TipoColegio'].replace({'RELG': 'PRIV', 'OTHR': 'PUBL'}).fillna('PUBL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdAlumno                              0\n",
      "CicloLectivoDesCorta                  0\n",
      "Desercion                             0\n",
      "Genero                                0\n",
      "FechaNacimiento                       0\n",
      "Distrito                              0\n",
      "Provincia                             0\n",
      "Departamento                          0\n",
      "FamiliarResponsable                   0\n",
      "AnioNacimiento                        0\n",
      "CantParcialesDesaprobados             0\n",
      "CantFinalesDesaprobados               0\n",
      "ExcedeNotasDesaprobadasNoParcNoFin    0\n",
      "ExcedeMitadCursosDesaprobados         0\n",
      "ProgramaAlu                           0\n",
      "Colegio                               0\n",
      "TipoColegio                           0\n",
      "Anio                                  0\n",
      "Edad                                  0\n",
      "GrupoEdad                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 20)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.to_csv('cachimbos_2023_2_sin_nulos.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_modelo = ['Edad', 'Genero', 'Distrito', 'Provincia', 'Departamento', 'FamiliarResponsable', 'CantParcialesDesaprobados', 'CantFinalesDesaprobados','ExcedeNotasDesaprobadasNoParcNoFin', 'ExcedeMitadCursosDesaprobados','Desercion']\n",
    "df_modelo = df[variables_modelo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo = pd.get_dummies(df_modelo, columns=['Genero', 'Distrito', 'Provincia', 'Departamento', 'FamiliarResponsable', 'CantParcialesDesaprobados', 'CantFinalesDesaprobados','ExcedeNotasDesaprobadasNoParcNoFin', 'ExcedeMitadCursosDesaprobados'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACION DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de los datos en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_modelo.drop(columns=['Desercion'])\n",
    "y = df_modelo['Desercion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario que guarda las métricas\n",
    "metricas_dict = {\n",
    "    \"Modelo\": [],\n",
    "    \"Tipo_Data\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"AUC\": [],\n",
    "    \"F1-Score\": [],\n",
    "    \"Precisión\": [],\n",
    "    \"Recall\": [],\n",
    "    \"Puntuación\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSII7\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score,f1_score, precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "# Función para calcular métricas\n",
    "def calcular_metricas(model, X_test, y_test, nombre_modelo):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    puntuacion = (0.3 * accuracy) + (0.1 * precision) + (0.3 * recall) + (0.3 * f1) + (0.5 * auc)\n",
    "    \n",
    "    metricas_dict[\"Modelo\"].append(nombre_modelo)\n",
    "    metricas_dict[\"Tipo_Data\"].append(\"Data Original\")\n",
    "    metricas_dict[\"Accuracy\"].append(accuracy)\n",
    "    metricas_dict[\"AUC\"].append(auc)\n",
    "    metricas_dict[\"F1-Score\"].append(f1)\n",
    "    metricas_dict[\"Precisión\"].append(precision)\n",
    "    metricas_dict[\"Recall\"].append(recall)\n",
    "    metricas_dict[\"Puntuación\"].append((puntuacion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS SIN BALANCEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    (\"Regresión Logística\", LogisticRegression(max_iter=1000)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(eval_metric='logloss', random_state=42)),\n",
    "    (\"SVM\", SVC(probability=True, random_state=42)),\n",
    "    (\"KNN\",KNeighborsClassifier(n_neighbors=5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar los modelos\n",
    "for nombre_modelo, modelo in modelos:\n",
    "    modelo.fit(X_train, y_train)\n",
    "    calcular_metricas(modelo, X_test, y_test, nombre_modelo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS CON BALANCEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reentrenar modelos con datos balanceados\n",
    "for nombre_modelo, modelo in modelos:\n",
    "    modelo.fit(X_resampled, y_resampled)\n",
    "    calcular_metricas(modelo, X_test, y_test, f\"{nombre_modelo} (SMOTE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS CON BALANCEO Y AJUSTE DE HIPERPARAMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los hiperparámetros para cada modelo\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con modelos y sus respectivos grids\n",
    "modelos_param_grids = [\n",
    "    (\"Regresión Logística\", LogisticRegression(max_iter=1000), param_grid_lr),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42), param_grid_rf),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(eval_metric='logloss', random_state=42), param_grid_xgb),\n",
    "    (\"SVM\", SVC(probability=True, random_state=42), param_grid_svm),\n",
    "    (\"KNN\", KNeighborsClassifier(), param_grid_knn)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Regresión Logística: {'C': 10, 'solver': 'liblinear'}\n",
      "Mejores parámetros para Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mejores parámetros para XGBoost: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300}\n",
      "Mejores parámetros para SVM: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mejores parámetros para KNN: {'n_neighbors': 7, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Realizamos la búsqueda de hiperparámetros\n",
    "for nombre_modelo, modelo, param_grid in modelos_param_grids:\n",
    "    grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Entrenamos con los mejores hiperparámetros\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Mejores parámetros para {nombre_modelo}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Calculamos métricas con los mejores hiperparámetros\n",
    "    calcular_metricas(best_model, X_test, y_test, f\"{nombre_modelo} (Optimizado y con SMOTE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORTADO DE METRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas = pd.DataFrame(metricas_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Modelo      Tipo_Data  Accuracy  \\\n",
      "13                  SVM (Optimizado y con SMOTE)  Data Original  0.741758   \n",
      "2                                        XGBoost  Data Original  0.741758   \n",
      "10  Regresión Logística (Optimizado y con SMOTE)  Data Original  0.725275   \n",
      "12              XGBoost (Optimizado y con SMOTE)  Data Original  0.717033   \n",
      "8                                    SVM (SMOTE)  Data Original  0.736264   \n",
      "9                                    KNN (SMOTE)  Data Original  0.634615   \n",
      "0                            Regresión Logística  Data Original  0.752747   \n",
      "14                  KNN (Optimizado y con SMOTE)  Data Original  0.634615   \n",
      "5                    Regresión Logística (SMOTE)  Data Original  0.711538   \n",
      "7                                XGBoost (SMOTE)  Data Original  0.692308   \n",
      "11        Random Forest (Optimizado y con SMOTE)  Data Original  0.678571   \n",
      "1                                  Random Forest  Data Original  0.728022   \n",
      "6                          Random Forest (SMOTE)  Data Original  0.651099   \n",
      "4                                            KNN  Data Original  0.711538   \n",
      "3                                            SVM  Data Original  0.656593   \n",
      "\n",
      "         AUC  F1-Score  Precisión  Recall  Puntuación  \n",
      "13  0.743448  0.605042   0.637168   0.576    1.012281  \n",
      "2   0.767632  0.584071   0.653465   0.528    1.005311  \n",
      "10  0.747732  0.593496   0.603306   0.584    1.005028  \n",
      "12  0.741573  0.592885   0.585938   0.600    1.002356  \n",
      "8   0.750510  0.578947   0.640777   0.528    0.992296  \n",
      "9   0.724418  0.577778   0.478947   0.728    0.992222  \n",
      "0   0.761490  0.567308   0.710843   0.472    0.989446  \n",
      "14  0.713490  0.577778   0.478947   0.728    0.986757  \n",
      "5   0.739464  0.574899   0.581967   0.568    0.984260  \n",
      "7   0.740904  0.559055   0.550388   0.568    0.971299  \n",
      "11  0.745858  0.551724   0.529412   0.576    0.967759  \n",
      "1   0.746728  0.526316   0.654762   0.440    0.947142  \n",
      "6   0.730293  0.517110   0.492754   0.544    0.928085  \n",
      "4   0.703565  0.472362   0.635135   0.376    0.883266  \n",
      "3   0.756636  0.000000   0.000000   0.000    0.575296  \n"
     ]
    }
   ],
   "source": [
    "df_metricas = df_metricas.sort_values(by=\"Puntuación\", ascending=False)\n",
    "df_metricas.to_csv(os.path.join(ruta_output,'Modelo_Desercion_Metricas.csv'))\n",
    "print(df_metricas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
