{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CARGO DATAFRAMES BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ruta_export = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\export\"\n",
    "ruta_output = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\output\"\n",
    "ruta_sources = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\sources\"\n",
    "\n",
    "df_matriculados_2024_1 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2024_1.csv'))\n",
    "df_matriculados_2023_2 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2023_2.csv'))\n",
    "df_matriculados_2023_1 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2023_1.csv'))\n",
    "df_matriculados_2022_2 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2022_2.csv'))\n",
    "df_matriculados_2022_1 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2022_1.csv'))\n",
    "\n",
    "\n",
    "df_desertores_2023_2 = pd.read_csv(os.path.join(ruta_export,'Desertores_2023_2.csv'))\n",
    "\n",
    "df_variables = pd.read_csv(os.path.join(ruta_export,'DataMaestra_Estudiante.csv'))\n",
    "\n",
    "df_notas_2023_2 = pd.read_csv(os.path.join(ruta_sources,'DATA_DETALLE_NOTAS-2023-2.csv'))\n",
    "\n",
    "df_colegio_procedencia = pd.read_csv(\n",
    "    os.path.join(ruta_sources, 'DATA_COLEGIO_PROCEDENCIA.csv'),\n",
    "    header=None,  # Indica que el archivo no tiene cabeceras\n",
    "    names=['IdAlumno', 'Colegio', 'TipoColegio']  # Especificar las cabeceras manualmente\n",
    ")\n",
    "df_colegio_procedencia = df_colegio_procedencia.drop_duplicates(subset='IdAlumno')\n",
    "\n",
    "df_pagos_2023 = pd.read_csv(os.path.join(ruta_sources,'pagos cachimbos 2023-2.csv'))\n",
    "\n",
    "\n",
    "nota_aprobatoria = 13\n",
    "notas_desaprobadas = 4\n",
    "periodo = '2023-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULO VARIABLES NOTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Agrupar por IdAlumno, Curso, Actividad y calcular la nota máxima\n",
    "df_notas_maximas = df_notas_2023_2.groupby(['IdAlumno', 'Curso', 'Actividad'], as_index=False).agg(\n",
    "    NotaMaxima=('NotaActiv', 'max')\n",
    ")\n",
    "\n",
    "# Agrupar por IdAlumno y contar los registros de parciales y finales desaprobados\n",
    "df_cant_desaprobado_agrupado = df_notas_maximas.groupby('IdAlumno').agg(\n",
    "    CantParcialesDesaprobados=(\n",
    "        'Actividad', \n",
    "        lambda x: ((x == 'EVALUACION PARCIAL') & (df_notas_maximas.loc[x.index, 'NotaMaxima'] < nota_aprobatoria)).sum()\n",
    "    ),\n",
    "    CantFinalesDesaprobados=(\n",
    "        'Actividad', \n",
    "        lambda x: ((x == 'EVALUACION FINAL') & (df_notas_maximas.loc[x.index, 'NotaMaxima'] < nota_aprobatoria)).sum()\n",
    "    ),\n",
    "    # Columna auxiliar para contar las evaluaciones diferentes de PARCIAL y FINAL desaprobadas\n",
    "    CantNotasDesaprobadasNoParcNoFin=(\n",
    "        'Actividad', \n",
    "        lambda x: ((~x.isin(['EVALUACION PARCIAL', 'EVALUACION FINAL', 'EVALUACION DIAGNOSTICA'])) & (df_notas_maximas.loc[x.index, 'NotaMaxima'] < nota_aprobatoria)).sum()\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "# Crear la columna 'ExcedeNotasDesaprobadasNoParcNoFin'\n",
    "df_cant_desaprobado_agrupado['ExcedeNotasDesaprobadasNoParcNoFin'] = df_cant_desaprobado_agrupado['CantNotasDesaprobadasNoParcNoFin'].apply(\n",
    "    lambda x: 'SI' if x >= notas_desaprobadas else 'NO'\n",
    ")\n",
    "\n",
    "\n",
    "# Calcular la nota final para cada curso por alumno\n",
    "df_notas_2023_2['NotaFinalCurso'] = np.where(\n",
    "    df_notas_2023_2['Actividad'] != 'EVALUACION DIAGNOSTICA',\n",
    "    (df_notas_2023_2['Peso'] * df_notas_2023_2['NotaActiv']) / 100,\n",
    "    np.nan  # Ignoramos las actividades diagnósticas\n",
    ")\n",
    "\n",
    "# Agrupar por IdAlumno y Curso para obtener la nota final por curso\n",
    "df_notas_finales_por_curso = df_notas_2023_2.groupby(['IdAlumno', 'Curso']).agg(\n",
    "    NotaFinalCurso=('NotaFinalCurso', 'sum')  # Sumar las notas ponderadas por curso\n",
    ").reset_index()\n",
    "\n",
    "# Redondeo las notas a su entero más cercano para el posterior conteo \n",
    "df_notas_finales_por_curso['NotaFinalCurso'] = df_notas_finales_por_curso['NotaFinalCurso'].round()\n",
    "\n",
    "# Agrupar por IdAlumno y contar los cursos desaprobados\n",
    "df_cursos_desaprobados = df_notas_finales_por_curso.groupby('IdAlumno').agg(\n",
    "    CantCursosDesaprobados=(\n",
    "        'NotaFinalCurso', \n",
    "        lambda x: (x < nota_aprobatoria).sum()\n",
    "    ),\n",
    "    CantCursos=(\n",
    "        'NotaFinalCurso', \n",
    "        'count'  # Cuenta la cantidad de cursos\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "# Creamos la columna ExcedeMitadCursosDesaprobados\n",
    "df_cursos_desaprobados['ExcedeMitadCursosDesaprobados'] = df_cursos_desaprobados.apply(\n",
    "    lambda row: 'SI' if (row['CantCursosDesaprobados'] / row['CantCursos']) >= 0.5 else 'NO', axis=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Unir este resultado con el DataFrame anterior\n",
    "df_cant_desaprobado_agrupado = df_cant_desaprobado_agrupado.merge(\n",
    "    df_cursos_desaprobados, \n",
    "    on='IdAlumno', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_cant_desaprobado_agrupado = df_cant_desaprobado_agrupado.merge(\n",
    "    df_notas_2023_2[['IdAlumno', 'ProgramaAlu']].drop_duplicates(),  # Tomar IdAlumno y ProgramaAlu sin duplicados\n",
    "    on='IdAlumno',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Eliminar la columna 'CantNotasDesaprobadasNoParcNoFin' \n",
    "df_cursos_desaprobados.drop(columns=['CantCursosDesaprobados','CantCursos'], inplace=True)\n",
    "\n",
    "# Eliminar la columna 'CantNotasDesaprobadasNoParcNoFin' \n",
    "df_cant_desaprobado_agrupado.drop(columns=['CantNotasDesaprobadasNoParcNoFin'], inplace=True)\n",
    "\n",
    "\n",
    "# Visualizar el DataFrame final\n",
    "print(df_cant_desaprobado_agrupado.head())\n",
    "df_cant_desaprobado_agrupado.to_csv('PRUEBA_PAGOS.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para encontrar el registro específico\n",
    "resultado = df_cant_desaprobado_agrupado[df_cant_desaprobado_agrupado['ExcedeMitadCursosDesaprobados'] == 'SI']\n",
    "\n",
    "# Verifica el resultado\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULO DE VARIABLES DE PAGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pagos_2023['FECHA_VENCIMIENTO'] = pd.to_datetime(df_pagos_2023['FECHA_VENCIMIENTO'])\n",
    "df_pagos_2023['FECHA_TRANSACCION'] = pd.to_datetime(df_pagos_2023['FECHA_TRANSACCION'])\n",
    "\n",
    "# Paso 1: Agrupar por IdAlumno y contar la cantidad de pagos (CantArmadas)\n",
    "df_agrupado = df_pagos_2023.groupby('IdAlumno').agg(\n",
    "    CantArmadas=('IdAlumno', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# Paso 2: Calcular CantArmadasRetraso7dias (transacciones con retraso mayor a 7 días)\n",
    "df_pagos_2023['Retraso'] = (df_pagos_2023['FECHA_TRANSACCION'] - df_pagos_2023['FECHA_VENCIMIENTO']).dt.days\n",
    "df_pagos_2023['RetrasoMayor7Dias'] = df_pagos_2023['Retraso'] > 7\n",
    "\n",
    "# Agrupar por IdAlumno y contar las transacciones con retraso mayor a 7 días\n",
    "df_retraso = df_pagos_2023.groupby('IdAlumno').agg(\n",
    "    CantArmadasRetraso7dias=('RetrasoMayor7Dias', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Paso 3: Unir ambos DataFrames (df_agrupado y df_retraso)\n",
    "df_resultado_pagos = pd.merge(df_agrupado, df_retraso, on='IdAlumno', how='left')\n",
    "\n",
    "# Paso 4: Crear el nuevo campo con la lógica Si/No\n",
    "df_resultado_pagos['ExcedePagosAtrasados'] = df_resultado_pagos.apply(\n",
    "    lambda row: 1 if row['CantArmadasRetraso7dias'] >= (row['CantArmadas'] / 2) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df_resultado_pagos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDENTIFICO LOS ESTUDIANTES A PREDECIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir todos los periodos anteriores en un solo dataframe\n",
    "df_matriculados_anteriores = pd.concat([df_matriculados_2023_1, df_matriculados_2022_2, df_matriculados_2022_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nuevos_matriculados_2023_2 = df_matriculados_2023_2[~df_matriculados_2023_2['IdAlumno'].isin(df_matriculados_anteriores['IdAlumno'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para encontrar el registro específico\n",
    "resultado = df_nuevos_matriculados_2023_2[df_nuevos_matriculados_2023_2['IdAlumno'] == 100118394]\n",
    "\n",
    "# Verifica el resultado\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_nuevos_matriculados_2023_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_variables.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables CRM\n",
    "df = pd.merge(df_nuevos_matriculados_2023_2, df_variables, on='IdAlumno', how='left')\n",
    "\n",
    "#Variables Notas\n",
    "df = pd.merge(df, df_cant_desaprobado_agrupado, on='IdAlumno', how='left')\n",
    "\n",
    "#Colegio Procedencia\n",
    "df = pd.merge(df, df_colegio_procedencia, on='IdAlumno', how='left')\n",
    "\n",
    "#Variables Pagos\n",
    "df = pd.merge(df, df_resultado_pagos, on='IdAlumno', how='left')\n",
    "\n",
    "# columna objetivo\n",
    "df['Desercion'] = df['IdAlumno'].isin(df_desertores_2023_2['IdAlumno']).astype(int)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN GENERO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la cuenta de cada género y de los valores nulos\n",
    "conteo_generos = df['Genero'].value_counts(dropna=False)\n",
    "count_f = conteo_generos.get('F', 0)  # Cantidad de F\n",
    "count_m = conteo_generos.get('M', 0)  # Cantidad de M\n",
    "total_blancos = conteo_generos.get(np.nan, 0)  # Cantidad de valores nulos\n",
    "\n",
    "# Ahora, calculamos la distribución equitativa\n",
    "if total_blancos > 0:\n",
    "    # Proporciones de cada género\n",
    "    proporciones_f = count_f / (count_f + count_m)\n",
    "    proporciones_m = count_m / (count_f + count_m)\n",
    "\n",
    "    # Cálculo de cuántos géneros se asignarán a los valores nulos\n",
    "    asignacion_f = int(total_blancos * proporciones_f)\n",
    "    asignacion_m = total_blancos - asignacion_f  # Lo que queda se asigna a M\n",
    "\n",
    "    # Rellenar los valores nulos en el DataFrame\n",
    "    df.loc[df['Genero'].isna(), 'Genero'] = ['F'] * asignacion_f + ['M'] * asignacion_m\n",
    "\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN FECHA DE NACIMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar cuántos valores nulos hay en FechaNacimiento\n",
    "n = df['FechaNacimiento'].isnull().sum()\n",
    "\n",
    "# Función para generar fechas aleatorias en el formato 'YYYY-MM-DD'\n",
    "def generar_fecha_aleatoria(n):\n",
    "    fechas = []\n",
    "    for _ in range(n):\n",
    "        anio = np.random.choice([2006, 2007])  # Años para tener 16 o 17 años en 2023\n",
    "        mes = np.random.randint(1, 13)  # Mes de 1 a 12\n",
    "        dia = np.random.randint(1, 29)  # Día de 1 a 28 (para simplificar)\n",
    "        fecha = f\"{anio}-{mes:02d}-{dia:02d}\"  # Formato 'YYYY-MM-DD'\n",
    "        fechas.append(fecha)\n",
    "    return fechas\n",
    "\n",
    "# Generar fechas aleatorias y rellenar los nulos\n",
    "fechas_aleatorias = generar_fecha_aleatoria(n)\n",
    "df.loc[df['FechaNacimiento'].isnull(), 'FechaNacimiento'] = fechas_aleatorias\n",
    "\n",
    "# Obtener el año de nacimiento de los nulos en FechaNacimiento\n",
    "df.loc[df['AnioNacimiento'].isnull(), 'AnioNacimiento'] = df['FechaNacimiento'].str.split('-').str[0].astype(int)\n",
    "\n",
    "#print(df)\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN DISTRITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de distritos para rellenar\n",
    "distritos = [\"ATE\", \"VILLA EL SALVADOR\", \"COMAS\", \"CHORRILLOS\", \"SAN MARTÍN DE PORRES\"]\n",
    "\n",
    "# Contar cuántos valores nulos hay en el campo 'Distrito'\n",
    "nulos_distrito = df['Distrito'].isnull().sum()\n",
    "\n",
    "# Calcular cuántos registros de cada distrito se necesitan\n",
    "if nulos_distrito > 0:\n",
    "    # Calcular cuántos distritos asignar a cada uno\n",
    "    asignaciones = [nulos_distrito // len(distritos)] * len(distritos)\n",
    "    \n",
    "    # Distribuir los restantes de manera aleatoria entre los distritos\n",
    "    for i in range(nulos_distrito % len(distritos)):\n",
    "        asignaciones[i] += 1\n",
    "\n",
    "    # Crear una lista con los distritos asignados\n",
    "    distritos_asignados = []\n",
    "    for distrito, cantidad in zip(distritos, asignaciones):\n",
    "        distritos_asignados.extend([distrito] * cantidad)\n",
    "\n",
    "    # Mezclar aleatoriamente la lista para distribuir uniformemente\n",
    "    np.random.shuffle(distritos_asignados)\n",
    "\n",
    "    # Rellenar los valores nulos en el DataFrame\n",
    "    df.loc[df['Distrito'].isnull(), 'Distrito'] = distritos_asignados\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN PROVINCIA NI DEPARTAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Provincia'] = df['Provincia'].fillna('LIMA')\n",
    "df['Departamento'] = df['Departamento'].fillna('LIMA')\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREO CAMPO EDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Edad'] = df['Anio'] - df['AnioNacimiento']\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las condiciones y sus correspondientes etiquetas\n",
    "condiciones = [\n",
    "    (df['Edad'] <= 18),\n",
    "    (df['Edad'] > 18) & (df['Edad'] < 25),\n",
    "    (df['Edad'] >= 25)\n",
    "]\n",
    "\n",
    "etiquetas = ['MenosDe18', 'Entre18y25', 'Mayor25']\n",
    "\n",
    "# Crear la nueva columna 'GrupoEdad' con las etiquetas según las condiciones, usando un valor por defecto como ''\n",
    "df['GrupoEdad'] = np.select(condiciones, etiquetas, default='')\n",
    "\n",
    "# Verificar los resultados\n",
    "print(df[['Edad', 'GrupoEdad']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO EL FAMILIAR RESPONSABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filas donde FamiliarResponsable es nulo\n",
    "mask = df['FamiliarResponsable'].isnull()\n",
    "\n",
    "# Aplicar la condición solo a esas filas\n",
    "df.loc[mask, 'FamiliarResponsable'] = df.loc[mask, 'Edad'].apply(lambda x: 'Apoderado' if x <= 18 else 'Alumno')\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relleno el tipo de colegio de procedencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TipoColegio'] = df_colegio_procedencia['TipoColegio'].replace({'RELG': 'PRIV', 'OTHR': 'PUBL'}).fillna('PUBL')\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.to_csv('cachimbos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_modelo = ['IdAlumno',\n",
    "                    'Edad', \n",
    "                    'Genero', \n",
    "                    'Distrito', \n",
    "                    'Provincia', \n",
    "                    'Departamento', \n",
    "                    'FamiliarResponsable', \n",
    "                    'CantParcialesDesaprobados', \n",
    "                    'CantFinalesDesaprobados',\n",
    "                    'ExcedeNotasDesaprobadasNoParcNoFin',\n",
    "                    'ExcedeMitadCursosDesaprobados',\n",
    "                    'GrupoEdad',\n",
    "                    'ExcedePagosAtrasados',\n",
    "                    'TipoColegio', \n",
    "                    'Desercion']\n",
    "df_modelo = df[variables_modelo]\n",
    "\n",
    "# Separar IdAlumno\n",
    "id_alumno = df_modelo['IdAlumno']\n",
    "\n",
    "# Convertir variables categóricas en variables dummy\n",
    "df_modelo = pd.get_dummies(df_modelo.drop(columns=['IdAlumno']), \n",
    "                            columns=['Genero', \n",
    "                                     'Distrito', \n",
    "                                     'Provincia', \n",
    "                                     'Departamento', \n",
    "                                     'FamiliarResponsable', \n",
    "                                     'CantParcialesDesaprobados', \n",
    "                                     'CantFinalesDesaprobados',\n",
    "                                     'ExcedeNotasDesaprobadasNoParcNoFin', \n",
    "                                     'ExcedeMitadCursosDesaprobados',\n",
    "                                     'GrupoEdad', \n",
    "                                     'ExcedePagosAtrasados', \n",
    "                                     'TipoColegio'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACION DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de los datos en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_modelo.drop(columns=['Desercion'])\n",
    "y = df_modelo['Desercion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix,f1_score, precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import shap\n",
    "\n",
    "# Diccionario que guarda las métricas\n",
    "metricas_dict = {\n",
    "    \"Modelo\": [],\n",
    "    \"Tipo_Data\": [],\n",
    "    \"Exactitud\": [],\n",
    "    \"AUC\": [],\n",
    "    \"F1-Score\": [],\n",
    "    \"Precisión\": [],\n",
    "    \"Recall\": [],\n",
    "    \"Puntuación\": []\n",
    "}\n",
    "\n",
    "predicciones_dict = {}\n",
    "modelos_dict = {}  # Diccionario para guardar los modelos entrenados\n",
    "probabilidades_dict = {}\n",
    "\n",
    "# Función para calcular métricas\n",
    "def calcular_metricas(model,flg_grid_search, X_train, y_train, X_test, y_test, nombre_modelo):\n",
    "\n",
    "    if flg_grid_search == 0: #Si no es grid search yo lo entreno\n",
    "        # Entrenar el modelo con el conjunto de entrenamiento\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Obtener probabilidades de deserción\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidad de la clase positiva (deserción)\n",
    "\n",
    "    # Hacer predicciones en todo el conjunto de datos\n",
    "    y_pred_completo = model.predict(X)\n",
    "\n",
    "    # Hacer predicciones en todo el conjunto de datos para almacenar el % de probabilidad completo\n",
    "    y_prob_completo = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Calculo de métrcias\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    puntuacion = (0.3 * accuracy) + (0.1 * precision) + (0.3 * recall) + (0.2 * f1) + (0.4 * auc)\n",
    "    \n",
    "    metricas_dict[\"Modelo\"].append(nombre_modelo)\n",
    "    metricas_dict[\"Tipo_Data\"].append(\"Data Original\")\n",
    "    metricas_dict[\"Exactitud\"].append(accuracy)\n",
    "    metricas_dict[\"AUC\"].append(auc)\n",
    "    metricas_dict[\"F1-Score\"].append(f1)\n",
    "    metricas_dict[\"Precisión\"].append(precision)\n",
    "    metricas_dict[\"Recall\"].append(recall)\n",
    "    metricas_dict[\"Puntuación\"].append((puntuacion))\n",
    "\n",
    "    # Almacenar las predicciones en un diccionario\n",
    "    predicciones_dict[nombre_modelo] = y_pred_completo\n",
    "\n",
    "    # Almacenar las predicciones % en un diccionario\n",
    "    probabilidades_dict[nombre_modelo] = y_prob_completo\n",
    "\n",
    "    # Guardar el modelo entrenado en el diccionario\n",
    "    modelos_dict[nombre_modelo] = model  # Aquí guardamos el modelo\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS SIN BALANCEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    (\"Regresión Logística\", LogisticRegression(max_iter=1000)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(eval_metric='logloss', random_state=42)),\n",
    "    (\"SVM\", SVC(probability=True, random_state=42)),\n",
    "    (\"KNN\",KNeighborsClassifier(n_neighbors=5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar los modelos\n",
    "for nombre_modelo, modelo in modelos:\n",
    "    calcular_metricas(modelo,0,X_train,y_train, X_test, y_test, nombre_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS CON BALANCEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reentrenar modelos con datos balanceados\n",
    "for nombre_modelo, modelo in modelos:\n",
    "    calcular_metricas(modelo,0,X_resampled, y_resampled, X_test, y_test, f\"{nombre_modelo} (SMOTE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS CON BALANCEO Y AJUSTE DE HIPERPARAMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los hiperparámetros para cada modelo\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con modelos y sus respectivos grids\n",
    "modelos_param_grids = [\n",
    "    (\"Regresión Logística\", LogisticRegression(max_iter=1000), param_grid_lr),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42), param_grid_rf),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(eval_metric='logloss', random_state=42), param_grid_xgb),\n",
    "    (\"SVM\", SVC(probability=True, random_state=42), param_grid_svm),\n",
    "    (\"KNN\", KNeighborsClassifier(), param_grid_knn)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la búsqueda de hiperparámetros\n",
    "for nombre_modelo, modelo, param_grid in modelos_param_grids:\n",
    "    grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    \n",
    "    # Entrenamos con los mejores hiperparámetros\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Mejores parámetros para {nombre_modelo}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Calculamos métricas con los mejores hiperparámetros\n",
    "    calcular_metricas(best_model,1,X_resampled,y_resampled, X_test, y_test, f\"{nombre_modelo} (Optimizado y con SMOTE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORTADO DE METRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas = pd.DataFrame(metricas_dict)\n",
    "\n",
    "df_metricas = df_metricas.sort_values(by=\"Puntuación\", ascending=False)\n",
    "df_metricas.to_csv(os.path.join(ruta_output,'Modelo_Desercion_Metricas.csv'))\n",
    "print(df_metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el modelo ganador basado en la puntuación más alta\n",
    "modelo_ganador_idx = df_metricas['Puntuación'].idxmax()\n",
    "modelo_ganador = df_metricas.loc[modelo_ganador_idx]\n",
    "nombre_modelo_ganador = modelo_ganador[\"Modelo\"]\n",
    "\n",
    "print(f\"El modelo ganador es: {nombre_modelo_ganador}\")\n",
    "print(modelo_ganador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predicciones_dict[nombre_modelo_ganador]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con IdAlumno y las predicciones\n",
    "predicciones_df = pd.DataFrame({\n",
    "    'IdAlumno': id_alumno.loc[X.index],  # Usar índices de X\n",
    "    'Prediccion': predicciones_dict[nombre_modelo_ganador],\n",
    "    'Prediccion_Probabilidad': probabilidades_dict[nombre_modelo_ganador]\n",
    "})\n",
    "\n",
    "dataset_base = df[variables_modelo]\n",
    "\n",
    "resultado_final = pd.merge(predicciones_df,dataset_base,on='IdAlumno',how='left') \n",
    "\n",
    "print(resultado_final.shape)\n",
    "print(resultado_final)\n",
    "\n",
    "resultado_final.to_csv(os.path.join(ruta_output,'Prediccion.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_modelo_ganador = modelos_dict[nombre_modelo_ganador]\n",
    "print(obj_modelo_ganador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener coeficientes\n",
    "coeficientes = obj_modelo_ganador.coef_[0]  # Para SVM lineales\n",
    "importancia_features = pd.Series(coeficientes, index=X_train.columns)\n",
    "importancia_features.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "# Mostrar las características más importantes\n",
    "print(type(importancia_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el explainer para el modelo SVM\n",
    "explainer = shap.LinearExplainer(obj_modelo_ganador, X)\n",
    "\n",
    "# Calcular los valores SHAP\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "print(len(shap_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los valores SHAP en un DataFrame\n",
    "shap_df = pd.DataFrame(shap_values, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar la columna 'IdAlumno'\n",
    "shap_df['IdAlumno'] = id_alumno.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_df)\n",
    "shap_df.to_csv(os.path.join(ruta_output,'Impacto_Variables.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame para el IdAlumno específico\n",
    "id_alumno_especifico = 100014115\n",
    "resultado_filtrado = shap_df.loc[shap_df['IdAlumno'] == id_alumno_especifico]\n",
    "\n",
    "# Mostrar el resultado filtrado\n",
    "#print(resultado_filtrado)\n",
    "print(display(resultado_filtrado))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
