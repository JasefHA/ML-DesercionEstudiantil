{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CARGO DATAFRAMES BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ruta_export = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\export\"\n",
    "ruta_output = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\output\"\n",
    "ruta_sources = r\"C:\\Users\\MSII7\\Documents\\Jasef\\Desercion\\sources\"\n",
    "\n",
    "df_matriculados_2023_2 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2023_2.csv'))\n",
    "df_matriculados_2023_1 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2023_1.csv'))\n",
    "df_matriculados_2022_2 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2022_2.csv'))\n",
    "df_matriculados_2022_1 = pd.read_csv(os.path.join(ruta_export,'Matriculados_2022_1.csv'))\n",
    "df_desertores_2023_2 = pd.read_csv(os.path.join(ruta_export,'Desertores_2023_2.csv'))\n",
    "df_variables = pd.read_csv(os.path.join(ruta_export,'DataMaestra_Estudiante.csv'))\n",
    "df_notas_2023_2 = pd.read_csv(os.path.join(ruta_sources,'DATA_DETALLE_NOTAS-2023-2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of          IdAlumno  CantParcialesDesaprobados  CantFinalesDesaprobados\n",
      "0       100002894                          0                        0\n",
      "1       100003558                          2                        3\n",
      "2       100003932                          0                        0\n",
      "3       100003946                          1                        1\n",
      "4       100003989                          0                        0\n",
      "...           ...                        ...                      ...\n",
      "14861  4200810288                          0                        0\n",
      "14862  4201010209                          0                        0\n",
      "14863  4201010528                          2                        3\n",
      "14864  4201010550                          4                        4\n",
      "14865  4201011098                          0                        0\n",
      "\n",
      "[14866 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "df_cant_desaprobado_agrupado = df_notas_2023_2.groupby('IdAlumno').agg(\n",
    "    CantParcialesDesaprobados=(\n",
    "        'Actividad', \n",
    "        lambda x: ((x == 'EVALUACION PARCIAL') & (df_notas_2023_2.loc[x.index, 'NotaActiv'] < 11)).sum()\n",
    "    ),\n",
    "    CantFinalesDesaprobados=(\n",
    "        'Actividad', \n",
    "        lambda x: ((x == 'EVALUACION FINAL') & (df_notas_2023_2.loc[x.index, 'NotaActiv'] < 11)).sum()\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "print(df_cant_desaprobado_agrupado.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir todos los periodos anteriores en un solo dataframe\n",
    "df_matriculados_anteriores = pd.concat([df_matriculados_2023_1, df_matriculados_2022_2, df_matriculados_2022_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nuevos_matriculados_2023_2 = df_matriculados_2023_2[~df_matriculados_2023_2['IdAlumno'].isin(df_matriculados_anteriores['IdAlumno'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CicloLectivoDesCorta, IdAlumno, Anio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame para encontrar el registro específico\n",
    "resultado = df_nuevos_matriculados_2023_2[df_nuevos_matriculados_2023_2['IdAlumno'] == 100118394]\n",
    "\n",
    "# Verifica el resultado\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1205, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_nuevos_matriculados_2023_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IdAlumno                   0\n",
      "Genero                     0\n",
      "FechaNacimiento            0\n",
      "Distrito                   0\n",
      "Provincia                  0\n",
      "Departamento               0\n",
      "FamiliarResponsable    20211\n",
      "AnioNacimiento             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_variables.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CicloLectivoDesCorta   IdAlumno  Anio Genero FechaNacimiento Distrito  \\\n",
      "0               2023-2  100004070  2023    NaN             NaN      NaN   \n",
      "1               2023-2  100008630  2023    NaN             NaN      NaN   \n",
      "2               2023-2  100009785  2023    NaN             NaN      NaN   \n",
      "3               2023-2  100011191  2023    NaN             NaN      NaN   \n",
      "4               2023-2  100012563  2023    NaN             NaN      NaN   \n",
      "\n",
      "  Provincia Departamento FamiliarResponsable  AnioNacimiento  \\\n",
      "0       NaN          NaN                 NaN             NaN   \n",
      "1       NaN          NaN                 NaN             NaN   \n",
      "2       NaN          NaN                 NaN             NaN   \n",
      "3       NaN          NaN                 NaN             NaN   \n",
      "4       NaN          NaN                 NaN             NaN   \n",
      "\n",
      "   CantParcialesDesaprobados  CantFinalesDesaprobados  Desercion  \n",
      "0                          0                        0          0  \n",
      "1                          0                        0          0  \n",
      "2                          2                        1          0  \n",
      "3                          2                        4          1  \n",
      "4                          0                        0          1  \n"
     ]
    }
   ],
   "source": [
    "#Variables CRM\n",
    "df = pd.merge(df_nuevos_matriculados_2023_2, df_variables, on='IdAlumno', how='left')\n",
    "\n",
    "#Parciales Desaprobados\n",
    "df = pd.merge(df, df_cant_desaprobado_agrupado, on='IdAlumno', how='left')\n",
    "\n",
    "# columna objetivo\n",
    "df['Desercion'] = df['IdAlumno'].isin(df_desertores_2023_2['IdAlumno']).astype(int)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN GENERO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CicloLectivoDesCorta           0\n",
      "IdAlumno                       0\n",
      "Anio                           0\n",
      "Genero                         0\n",
      "FechaNacimiento               90\n",
      "Distrito                      90\n",
      "Provincia                     90\n",
      "Departamento                  90\n",
      "FamiliarResponsable          742\n",
      "AnioNacimiento                90\n",
      "CantParcialesDesaprobados      0\n",
      "CantFinalesDesaprobados        0\n",
      "Desercion                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la cuenta de cada género y de los valores nulos\n",
    "conteo_generos = df['Genero'].value_counts(dropna=False)\n",
    "count_f = conteo_generos.get('F', 0)  # Cantidad de F\n",
    "count_m = conteo_generos.get('M', 0)  # Cantidad de M\n",
    "total_blancos = conteo_generos.get(np.nan, 0)  # Cantidad de valores nulos\n",
    "\n",
    "# Ahora, calculamos la distribución equitativa\n",
    "if total_blancos > 0:\n",
    "    # Proporciones de cada género\n",
    "    proporciones_f = count_f / (count_f + count_m)\n",
    "    proporciones_m = count_m / (count_f + count_m)\n",
    "\n",
    "    # Cálculo de cuántos géneros se asignarán a los valores nulos\n",
    "    asignacion_f = int(total_blancos * proporciones_f)\n",
    "    asignacion_m = total_blancos - asignacion_f  # Lo que queda se asigna a M\n",
    "\n",
    "    # Rellenar los valores nulos en el DataFrame\n",
    "    df.loc[df['Genero'].isna(), 'Genero'] = ['F'] * asignacion_f + ['M'] * asignacion_m\n",
    "\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN FECHA DE NACIMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CicloLectivoDesCorta           0\n",
      "IdAlumno                       0\n",
      "Anio                           0\n",
      "Genero                         0\n",
      "FechaNacimiento                0\n",
      "Distrito                      90\n",
      "Provincia                     90\n",
      "Departamento                  90\n",
      "FamiliarResponsable          742\n",
      "AnioNacimiento                 0\n",
      "CantParcialesDesaprobados      0\n",
      "CantFinalesDesaprobados        0\n",
      "Desercion                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar cuántos valores nulos hay en FechaNacimiento\n",
    "n = df['FechaNacimiento'].isnull().sum()\n",
    "\n",
    "# Función para generar fechas aleatorias en el formato 'YYYY-MM-DD'\n",
    "def generar_fecha_aleatoria(n):\n",
    "    fechas = []\n",
    "    for _ in range(n):\n",
    "        anio = np.random.choice([2006, 2007])  # Años para tener 16 o 17 años en 2023\n",
    "        mes = np.random.randint(1, 13)  # Mes de 1 a 12\n",
    "        dia = np.random.randint(1, 29)  # Día de 1 a 28 (para simplificar)\n",
    "        fecha = f\"{anio}-{mes:02d}-{dia:02d}\"  # Formato 'YYYY-MM-DD'\n",
    "        fechas.append(fecha)\n",
    "    return fechas\n",
    "\n",
    "# Generar fechas aleatorias y rellenar los nulos\n",
    "fechas_aleatorias = generar_fecha_aleatoria(n)\n",
    "df.loc[df['FechaNacimiento'].isnull(), 'FechaNacimiento'] = fechas_aleatorias\n",
    "\n",
    "# Obtener el año de nacimiento de los nulos en FechaNacimiento\n",
    "df.loc[df['AnioNacimiento'].isnull(), 'AnioNacimiento'] = df['FechaNacimiento'].str.split('-').str[0].astype(int)\n",
    "\n",
    "#print(df)\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN DISTRITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CicloLectivoDesCorta           0\n",
      "IdAlumno                       0\n",
      "Anio                           0\n",
      "Genero                         0\n",
      "FechaNacimiento                0\n",
      "Distrito                       0\n",
      "Provincia                     90\n",
      "Departamento                  90\n",
      "FamiliarResponsable          742\n",
      "AnioNacimiento                 0\n",
      "CantParcialesDesaprobados      0\n",
      "CantFinalesDesaprobados        0\n",
      "Desercion                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lista de distritos para rellenar\n",
    "distritos = [\"ATE\", \"VILLA EL SALVADOR\", \"COMAS\", \"CHORRILLOS\", \"SAN MARTÍN DE PORRES\"]\n",
    "\n",
    "# Contar cuántos valores nulos hay en el campo 'Distrito'\n",
    "nulos_distrito = df['Distrito'].isnull().sum()\n",
    "\n",
    "# Calcular cuántos registros de cada distrito se necesitan\n",
    "if nulos_distrito > 0:\n",
    "    # Calcular cuántos distritos asignar a cada uno\n",
    "    asignaciones = [nulos_distrito // len(distritos)] * len(distritos)\n",
    "    \n",
    "    # Distribuir los restantes de manera aleatoria entre los distritos\n",
    "    for i in range(nulos_distrito % len(distritos)):\n",
    "        asignaciones[i] += 1\n",
    "\n",
    "    # Crear una lista con los distritos asignados\n",
    "    distritos_asignados = []\n",
    "    for distrito, cantidad in zip(distritos, asignaciones):\n",
    "        distritos_asignados.extend([distrito] * cantidad)\n",
    "\n",
    "    # Mezclar aleatoriamente la lista para distribuir uniformemente\n",
    "    np.random.shuffle(distritos_asignados)\n",
    "\n",
    "    # Rellenar los valores nulos en el DataFrame\n",
    "    df.loc[df['Distrito'].isnull(), 'Distrito'] = distritos_asignados\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO LOS QUE NO TIENEN PROVINCIA NI DEPARTAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CicloLectivoDesCorta           0\n",
      "IdAlumno                       0\n",
      "Anio                           0\n",
      "Genero                         0\n",
      "FechaNacimiento                0\n",
      "Distrito                       0\n",
      "Provincia                      0\n",
      "Departamento                   0\n",
      "FamiliarResponsable          742\n",
      "AnioNacimiento                 0\n",
      "CantParcialesDesaprobados      0\n",
      "CantFinalesDesaprobados        0\n",
      "Desercion                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Provincia'] = df['Provincia'].fillna('LIMA')\n",
    "df['Departamento'] = df['Departamento'].fillna('LIMA')\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREO CAMPO EDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CicloLectivoDesCorta           0\n",
      "IdAlumno                       0\n",
      "Anio                           0\n",
      "Genero                         0\n",
      "FechaNacimiento                0\n",
      "Distrito                       0\n",
      "Provincia                      0\n",
      "Departamento                   0\n",
      "FamiliarResponsable          742\n",
      "AnioNacimiento                 0\n",
      "CantParcialesDesaprobados      0\n",
      "CantFinalesDesaprobados        0\n",
      "Desercion                      0\n",
      "Edad                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Edad'] = df['Anio'] - df['AnioNacimiento']\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELLENO EL FAMILIAR RESPONSABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CicloLectivoDesCorta         0\n",
      "IdAlumno                     0\n",
      "Anio                         0\n",
      "Genero                       0\n",
      "FechaNacimiento              0\n",
      "Distrito                     0\n",
      "Provincia                    0\n",
      "Departamento                 0\n",
      "FamiliarResponsable          0\n",
      "AnioNacimiento               0\n",
      "CantParcialesDesaprobados    0\n",
      "CantFinalesDesaprobados      0\n",
      "Desercion                    0\n",
      "Edad                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filas donde FamiliarResponsable es nulo\n",
    "mask = df['FamiliarResponsable'].isnull()\n",
    "\n",
    "# Aplicar la condición solo a esas filas\n",
    "df.loc[mask, 'FamiliarResponsable'] = df.loc[mask, 'Edad'].apply(lambda x: 'Apoderado' if x <= 18 else 'Alumno')\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_modelo = ['Edad', 'Genero', 'Distrito', 'Provincia', 'Departamento', 'FamiliarResponsable', 'CantParcialesDesaprobados', 'CantFinalesDesaprobados', 'Desercion']\n",
    "df_modelo = df[variables_modelo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo = pd.get_dummies(df_modelo, columns=['Genero', 'Distrito', 'Provincia', 'Departamento', 'FamiliarResponsable', 'CantParcialesDesaprobados', 'CantFinalesDesaprobados'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREACION DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#División de los datos en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_modelo.drop(columns=['Desercion'])\n",
    "y = df_modelo['Desercion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario que guarda las métricas\n",
    "metricas_dict = {\n",
    "    \"Modelo\": [],\n",
    "    \"Tipo_Data\": [],\n",
    "    \"Exactitud\": [],\n",
    "    \"AUC\": [],\n",
    "    \"F1-Score\": [],\n",
    "    \"Precisión\": [],\n",
    "    \"Recall\": [],\n",
    "    #\"Verdaderos Negativos\": [],\n",
    "    #\"Falsos Positivos\": [],\n",
    "    #\"Falsos Negativos\": [],\n",
    "    #Verdaderos Positivos\": [],\n",
    "    \"Puntuación\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix,f1_score, precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Función para calcular métricas\n",
    "def calcular_metricas(model, X_test, y_test, nombre_modelo):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    puntuacion = (0.1 * accuracy) + (0.2 * precision) + (0.5 * recall) + (0.3 * f1) + (0.2 * auc)\n",
    "    \n",
    "    metricas_dict[\"Modelo\"].append(nombre_modelo)\n",
    "    metricas_dict[\"Tipo_Data\"].append(\"Data Original\")\n",
    "    metricas_dict[\"Exactitud\"].append(accuracy)\n",
    "    metricas_dict[\"AUC\"].append(auc)\n",
    "    metricas_dict[\"F1-Score\"].append(f1)\n",
    "    metricas_dict[\"Precisión\"].append(precision)\n",
    "    metricas_dict[\"Recall\"].append(recall)\n",
    "    metricas_dict[\"Puntuación\"].append((puntuacion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS SIN BALANCEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    (\"Regresión Logística\", LogisticRegression(max_iter=1000)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(eval_metric='logloss', random_state=42)),\n",
    "    (\"SVM\", SVC(probability=True, random_state=42)),\n",
    "    (\"KNN\",KNeighborsClassifier(n_neighbors=5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar los modelos\n",
    "for nombre_modelo, modelo in modelos:\n",
    "    modelo.fit(X_train, y_train)\n",
    "    calcular_metricas(modelo, X_test, y_test, nombre_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS CON BALANCEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reentrenar modelos con datos balanceados\n",
    "for nombre_modelo, modelo in modelos:\n",
    "    modelo.fit(X_resampled, y_resampled)\n",
    "    calcular_metricas(modelo, X_test, y_test, f\"{nombre_modelo} (SMOTE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS CON BALANCEO Y AJUSTE DE HIPERPARAMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los hiperparámetros para cada modelo\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con modelos y sus respectivos grids\n",
    "modelos_param_grids = [\n",
    "    (\"Regresión Logística\", LogisticRegression(max_iter=1000), param_grid_lr),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42), param_grid_rf),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(eval_metric='logloss', random_state=42), param_grid_xgb),\n",
    "    (\"SVM\", SVC(probability=True, random_state=42), param_grid_svm),\n",
    "    (\"KNN\", KNeighborsClassifier(), param_grid_knn)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Regresión Logística: {'C': 10, 'solver': 'liblinear'}\n",
      "Mejores parámetros para Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mejores parámetros para XGBoost: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}\n",
      "Mejores parámetros para SVM: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mejores parámetros para KNN: {'n_neighbors': 5, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Realizamos la búsqueda de hiperparámetros\n",
    "for nombre_modelo, modelo, param_grid in modelos_param_grids:\n",
    "    grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Entrenamos con los mejores hiperparámetros\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Mejores parámetros para {nombre_modelo}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Calculamos métricas con los mejores hiperparámetros\n",
    "    calcular_metricas(best_model, X_test, y_test, f\"{nombre_modelo} (Optimizado y con SMOTE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORTADO DE METRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Modelo      Tipo_Data  Exactitud  \\\n",
      "10  Regresión Logística (Optimizado y con SMOTE)  Data Original   0.781768   \n",
      "13                  SVM (Optimizado y con SMOTE)  Data Original   0.767956   \n",
      "5                    Regresión Logística (SMOTE)  Data Original   0.745856   \n",
      "0                            Regresión Logística  Data Original   0.754144   \n",
      "12              XGBoost (Optimizado y con SMOTE)  Data Original   0.715470   \n",
      "11        Random Forest (Optimizado y con SMOTE)  Data Original   0.729282   \n",
      "7                                XGBoost (SMOTE)  Data Original   0.707182   \n",
      "2                                        XGBoost  Data Original   0.715470   \n",
      "6                          Random Forest (SMOTE)  Data Original   0.701657   \n",
      "1                                  Random Forest  Data Original   0.704420   \n",
      "14                  KNN (Optimizado y con SMOTE)  Data Original   0.676796   \n",
      "9                                    KNN (SMOTE)  Data Original   0.674033   \n",
      "8                                    SVM (SMOTE)  Data Original   0.687845   \n",
      "4                                            KNN  Data Original   0.679558   \n",
      "3                                            SVM  Data Original   0.654696   \n",
      "\n",
      "         AUC  F1-Score  Precisión    Recall  Puntuación  \n",
      "10  0.795292  0.658009   0.690909  0.628099    0.886869  \n",
      "13  0.801361  0.631579   0.672897  0.595041    0.858642  \n",
      "5   0.791314  0.616667   0.621849  0.611570    0.848003  \n",
      "0   0.787507  0.565854   0.690476  0.479339    0.780437  \n",
      "12  0.747351  0.557940   0.580357  0.537190    0.773066  \n",
      "11  0.751603  0.558559   0.613861  0.512397    0.769787  \n",
      "7   0.742464  0.550847   0.565217  0.537190    0.766104  \n",
      "2   0.742207  0.546256   0.584906  0.512397    0.757045  \n",
      "6   0.731131  0.542373   0.556522  0.528926    0.754871  \n",
      "1   0.732468  0.528634   0.566038  0.495868    0.736667  \n",
      "14  0.626916  0.393782   0.527778  0.314050    0.573778  \n",
      "9   0.614211  0.391753   0.520548  0.314050    0.568906  \n",
      "8   0.674051  0.361582   0.571429  0.264463    0.558586  \n",
      "4   0.610027  0.340909   0.545455  0.247934    0.525292  \n",
      "3   0.707640  0.015748   0.166667  0.008264    0.249188  \n"
     ]
    }
   ],
   "source": [
    "df_metricas = pd.DataFrame(metricas_dict)\n",
    "\n",
    "df_metricas = df_metricas.sort_values(by=\"Puntuación\", ascending=False)\n",
    "df_metricas.to_csv(os.path.join(ruta_output,'Modelo_Desercion_Metricas.csv'))\n",
    "print(df_metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
